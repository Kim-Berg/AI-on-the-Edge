"""
Azure AI Foundry Local Startup Script
Checks connection and launches quality control demo
"""

import requests
import json
import time
import os
import sys

def check_azure_foundry_local():
    """Check if Azure AI Foundry Local is running"""
    endpoints = [
        {"url": "http://localhost:3928", "name": "Azure AI Foundry Local (default port)"},
        {"url": "http://localhost:1234", "name": "Azure AI Foundry Local (alt port)"},
        {"url": "http://127.0.0.1:3928", "name": "Azure AI Foundry Local (127.0.0.1)"},
        {"url": "http://localhost:11434", "name": "Ollama (compatibility mode)"}
    ]
    
    print("üîç Checking for Azure AI Foundry Local...")
    
    for endpoint in endpoints:
        try:
            print(f"   Testing {endpoint['name']}...")
            
            # Try multiple API paths
            api_paths = ["/v1/models", "/models", "/api/models", "/"]
            
            for path in api_paths:
                try:
                    response = requests.get(f"{endpoint['url']}{path}", timeout=3)
                    if response.status_code == 200:
                        print(f"‚úÖ Found service at: {endpoint['url']}")
                        
                        # Try to get models
                        if "models" in path:
                            try:
                                models = response.json()
                                if isinstance(models, dict) and 'data' in models:
                                    model_list = [model['id'] for model in models['data']]
                                elif isinstance(models, list):
                                    model_list = [model.get('id', model.get('name', str(model))) for model in models]
                                else:
                                    model_list = []
                                    
                                print(f"üìã Available models: {', '.join(model_list) if model_list else 'Service running, models list unavailable'}")
                                
                                # Check for vision-capable models
                                vision_models = [m for m in model_list if any(term in str(m).lower() 
                                    for term in ['vision', 'multimodal', 'gpt-4', 'phi-4', 'llava'])]
                                
                                if vision_models:
                                    print(f"üëÅÔ∏è Vision models found: {', '.join(vision_models)}")
                                else:
                                    print("‚ö†Ô∏è No vision models detected. Text analysis will be used.")
                                
                                return endpoint['url'], model_list
                            except:
                                print(f"‚úÖ Service running at {endpoint['url']} (models list unavailable)")
                                return endpoint['url'], []
                        else:
                            print(f"‚úÖ Service responding at {endpoint['url']}")
                            return endpoint['url'], []
                except requests.exceptions.RequestException:
                    continue
                    
        except requests.exceptions.RequestException:
            continue
    
    return None, []

def setup_instructions():
    """Display detailed setup instructions for Azure AI Foundry Local"""
    print("\nüìã Azure AI Foundry Local Setup Instructions:")
    print("=" * 60)
    print("1Ô∏è‚É£ Download and Install:")
    print("   ‚Ä¢ Visit: https://azure.microsoft.com/products/ai-foundry/")
    print("   ‚Ä¢ Or use: winget install Microsoft.AzureAIFoundryLocal")
    print("   ‚Ä¢ Or download from Microsoft Store")
    
    print("\n2Ô∏è‚É£ Start the Service:")
    print("   ‚Ä¢ Launch from Start Menu: 'Azure AI Foundry Local'")
    print("   ‚Ä¢ Or run in terminal: azure-ai-foundry-local")
    print("   ‚Ä¢ Service runs on port 3928 by default")
    
    print("\n3Ô∏è‚É£ Load a Model (Choose one):")
    print("   üéØ For Best Results (Vision-capable):")
    print("      ‚Ä¢ phi-4-multimodal-instruct")
    print("      ‚Ä¢ llama-3.2-11b-vision-instruct") 
    print("      ‚Ä¢ gpt-4-vision-preview")
    print("   üìù Text-only Models:")
    print("      ‚Ä¢ phi-4")
    print("      ‚Ä¢ llama-3.2-3b-instruct")
    
    print("\n4Ô∏è‚É£ Verify Installation:")
    print("   ‚Ä¢ Open browser to: http://localhost:3928")
    print("   ‚Ä¢ Should see Azure AI Foundry Local interface")
    
    print("\n5Ô∏è‚É£ Alternative Ports (if default doesn't work):")
    print("   ‚Ä¢ Port 1234 (LM Studio compatibility)")
    print("   ‚Ä¢ Port 11434 (Ollama compatibility)")

def main():
    """Main function to start the quality control demo"""
    print("üöÄ Azure AI Quality Control Demo")
    print("ü§ñ With Azure AI Foundry Local Integration")
    print("=" * 60)
    
    # Check Azure AI Foundry Local
    endpoint, models = check_azure_foundry_local()
    
    if not endpoint:
        print("‚ùå Azure AI Foundry Local not detected!")
        setup_instructions()
        print("\n" + "‚ö†Ô∏è" * 20)
        print("‚ö†Ô∏è IMPORTANT: Demo will run in SIMULATION mode without AI")
        print("‚ö†Ô∏è" * 20)
        
        choice = input("\nü§î Continue with simulation mode? (y/N): ").lower()
        if choice != 'y':
            print("ÔøΩ Set up Azure AI Foundry Local first, then re-run this script!")
            return
            
        print("ÔøΩüîÑ Starting simulation mode...")
        app_file = "quality_control_app.py"
    else:
        print(f"‚úÖ Connected to Azure AI Foundry Local: {endpoint}")
        
        if models:
            vision_models = [m for m in models if any(term in str(m).lower() 
                for term in ['vision', 'multimodal', 'gpt-4', 'phi-4', 'llava'])]
            
            if vision_models:
                print(f"üëÅÔ∏è Vision Analysis Available! Models: {', '.join(vision_models[:2])}")
                print("üéØ Demo will use AI-powered image defect detection!")
            else:
                print("üìù Text-based AI analysis will be used")
                print("üí° For best results, load a vision-capable model")
        
        print("üöÄ Starting enhanced demo with Azure AI Foundry Local...")
        app_file = "azure_ai_quality_control.py"
    
    print(f"\nüéØ Launching Application...")
    print("üåê Open browser to: http://localhost:5000")
    print("üõë Press Ctrl+C to stop")
    print("=" * 60)
    
    try:
        # Use subprocess for better error handling
        import subprocess
        result = subprocess.run([sys.executable, app_file], cwd=os.path.dirname(__file__))
        if result.returncode != 0:
            print(f"\n‚ùå Application exited with error code: {result.returncode}")
    except FileNotFoundError:
        print(f"‚ùå Could not find {app_file}")
        print("üí° Make sure you're running this script from the correct directory")
    except KeyboardInterrupt:
        print("\n\nüõë Demo stopped by user")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")

if __name__ == "__main__":
    main()