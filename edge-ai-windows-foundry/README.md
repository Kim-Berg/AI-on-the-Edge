# ğŸªŸ Windows AI Foundry Demo

A comprehensive showcase of local AI capabilities running directly on Windows devices through the Windows AI Foundry platform.

## ğŸš€ Features

- **ğŸ¤– Multi-Model Support**: Access to 7 different AI models with real-time switching
- **ğŸ¯ 8 AI Capabilities**: Text generation, code assistance, document analysis, creative writing, multimodal analysis, advanced reasoning, translation, and summarization
- **ğŸ”’ 100% Local Processing**: All AI operations run locally for complete privacy
- **âš¡ Real-time Performance**: Enhanced with timeout handling and auto-retry mechanisms
- **ğŸ“Š Model Performance Monitoring**: Real-time metrics and connection status
- **ğŸ¨ Interactive Interface**: Modern web UI with responsive design

## ğŸ¯ Available AI Capabilities

### Core Features
1. **ğŸ“ Text Generation** - Professional content creation and writing assistance
2. **ğŸ’» Code Assistance** - Multi-language programming help and code generation  
3. **ğŸ“„ Document Analysis** - Intelligent document processing and insights
4. **âœ¨ Creative Writing** - Stories, marketing content, and creative assistance
5. **ğŸ‘ï¸ Multimodal Analysis** - Visual and text content understanding
6. **ğŸ§  Advanced Reasoning** - Complex problem solving and logic
7. **ğŸŒ Translation** - Multi-language translation capabilities
8. **ğŸ“Š Summarization** - Document and text summarization

### Technical Highlights
- **7 AI Models**: Real-time switching between different AI models
- **Enhanced Timeouts**: Intelligent model-specific timeout handling (60s to 5+ minutes)
- **Auto-retry System**: Automatic recovery with 10-minute fallback timeouts
- **Connection Monitoring**: Real-time status updates with visual indicators
- **Session Management**: Fresh HTTP sessions prevent connection issues

## ğŸš€ Usage

1. **Start Windows AI Foundry Local** service first
2. **Select an AI Model** from the dropdown menu
3. **Choose a Capability** by clicking on any of the 8 cards
4. **Try Example Prompts** or create your own
5. **Generate Response** and watch real AI processing

### Model Performance
- **qwen2.5-0.5b-instruct**: Fastest responses (60s timeout)
- **Phi-3.5-mini-instruct**: Balanced performance (300s timeout)
- **Llama models**: Enhanced reasoning (300s timeout)
- **Mistral-7B**: Creative responses (400s timeout)
- **DeepSeek-R1**: Advanced reasoning (500s timeout)

## ğŸ“š Documentation

For complete setup instructions and troubleshooting, see the main [DEMO_INSTRUCTIONS.md](../DEMO_INSTRUCTIONS.md) file.