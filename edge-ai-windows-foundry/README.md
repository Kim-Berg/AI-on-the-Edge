# 🪟 Windows AI Foundry Demo

A comprehensive showcase of local AI capabilities running directly on Windows devices through the Windows AI Foundry platform.

## 🚀 Features

- **🤖 Multi-Model Support**: Access to 7 different AI models with real-time switching
- **🎯 8 AI Capabilities**: Text generation, code assistance, document analysis, creative writing, multimodal analysis, advanced reasoning, translation, and summarization
- **🔒 100% Local Processing**: All AI operations run locally for complete privacy
- **⚡ Real-time Performance**: Enhanced with timeout handling and auto-retry mechanisms
- **📊 Model Performance Monitoring**: Real-time metrics and connection status
- **🎨 Interactive Interface**: Modern web UI with responsive design

## 🎯 Available AI Capabilities

### Core Features
1. **📝 Text Generation** - Professional content creation and writing assistance
2. **💻 Code Assistance** - Multi-language programming help and code generation  
3. **📄 Document Analysis** - Intelligent document processing and insights
4. **✨ Creative Writing** - Stories, marketing content, and creative assistance
5. **👁️ Multimodal Analysis** - Visual and text content understanding
6. **🧠 Advanced Reasoning** - Complex problem solving and logic
7. **🌍 Translation** - Multi-language translation capabilities
8. **📊 Summarization** - Document and text summarization

### Technical Highlights
- **7 AI Models**: Real-time switching between different AI models
- **Enhanced Timeouts**: Intelligent model-specific timeout handling (60s to 5+ minutes)
- **Auto-retry System**: Automatic recovery with 10-minute fallback timeouts
- **Connection Monitoring**: Real-time status updates with visual indicators
- **Session Management**: Fresh HTTP sessions prevent connection issues

## 🚀 Usage

1. **Start Windows AI Foundry Local** service first
2. **Select an AI Model** from the dropdown menu
3. **Choose a Capability** by clicking on any of the 8 cards
4. **Try Example Prompts** or create your own
5. **Generate Response** and watch real AI processing

### Model Performance
- **qwen2.5-0.5b-instruct**: Fastest responses (60s timeout)
- **Phi-3.5-mini-instruct**: Balanced performance (300s timeout)
- **Llama models**: Enhanced reasoning (300s timeout)
- **Mistral-7B**: Creative responses (400s timeout)
- **DeepSeek-R1**: Advanced reasoning (500s timeout)

## 📚 Documentation

For complete setup instructions and troubleshooting, see the main [DEMO_INSTRUCTIONS.md](../DEMO_INSTRUCTIONS.md) file.